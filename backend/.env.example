# Application Configuration
APP_NAME=LegalEase
APP_VERSION=0.1.0
DEBUG=True

# Database Configuration
DATABASE_URL=postgresql+asyncpg://legalease:legalease@localhost:5432/legalease

# Redis Configuration
REDIS_URL=redis://localhost:6379/0

# Qdrant Configuration
QDRANT_URL=http://localhost:6333
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION=legalease_documents

# MinIO Configuration
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_BUCKET=legalease
MINIO_SECURE=False

# Celery Configuration
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# Security Configuration
SECRET_KEY=your-secret-key-here-change-in-production
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# AI/ML API Keys
# OpenAI API (Whisper fallback when WhisperX unavailable)
OPENAI_API_KEY=your-openai-api-key-here

# HuggingFace API Key (OPTIONAL - required only for pyannote speaker diarization models)
# Create token at: https://huggingface.co/settings/tokens
# Accept conditions at: https://huggingface.co/pyannote/segmentation-3.0
# Leave empty to use simple pause-based speaker detection instead
HF_TOKEN=

# Model Storage
# Pyannote models downloaded automatically on first run (requires HF_TOKEN above)
# If no token provided, falls back to simple heuristic diarization
# Models cached in: backend/models/pyannote/
MODEL_CACHE_DIR=models

# Transcription Configuration (Adaptive)
# WhisperX model selection - auto-detects based on available VRAM
# Options: auto, tiny, base, small, medium, large
# - auto: automatically selects based on GPU VRAM (recommended)
# - tiny: ~1GB VRAM, fastest but least accurate
# - base: ~2GB VRAM, fast and decent quality
# - small: ~3GB VRAM, balanced speed/quality
# - medium: ~5GB VRAM, high quality (default for auto with 8GB+ VRAM)
# - large: ~10GB VRAM, highest quality but slowest
WHISPER_MODEL=auto

# Batch size for WhisperX transcription (0 = auto-calculate based on VRAM)
# Larger batch = faster but more VRAM usage
# Auto-calculation: 4-32 based on model size and available VRAM
WHISPER_BATCH_SIZE=0

# Speaker Diarization (who said what)
# The system will automatically disable diarization if VRAM is insufficient
# Priority: 1) drop concurrency, 2) reduce model size, 3) disable diarization
ENABLE_DIARIZATION=true
DIARIZATION_MIN_SPEAKERS=2
DIARIZATION_MAX_SPEAKERS=5
# PERFORMANCE NOTE: Narrower speaker range = faster diarization
# - For interviews/2-person calls: Use 2-3 max (fastest)
# - For small meetings: Use 2-5 max (balanced, recommended)
# - For large meetings: Use 2-10 max (slower but more accurate)
PYANNOTE_MODEL=pyannote/speaker-diarization-3.1

# Speaker Name Inference (AI-powered speaker identification)
# Uses Ollama LLM to infer speaker names from conversation context
# WARNING: Concurrent Ollama requests can exhaust RAM/VRAM
# Solution: Redis semaphore limits concurrent requests (see OLLAMA_MAX_CONCURRENT_REQUESTS)
ENABLE_SPEAKER_NAME_INFERENCE=true

# Ollama LLM model for speaker name inference
# Options: llama3.1:latest, llama3.1:8b, llama3.2:1b (smaller/faster), etc.
# Smaller models = faster inference but potentially less accurate
OLLAMA_MODEL_SPEAKER_INFERENCE=llama3.1:latest

# Ollama Concurrency Control (prevents RAM/VRAM exhaustion)
# Maximum concurrent Ollama LLM requests across all workers
# - 1 = Sequential processing (safest, prevents timeouts)
# - 2+ = Parallel processing (requires sufficient RAM/VRAM)
# Recommendation: Keep at 1 for systems with <16GB RAM or <10GB VRAM
OLLAMA_MAX_CONCURRENT_REQUESTS=1

# Celery Worker Configuration
# Autoscaling: max_workers,min_workers (adapts to queue load)
# - System starts with 1 worker
# - Scales up to 4 workers when queue is busy
# - Scales down to 1 when idle
# - Automatically limited by VRAM constraints
CELERY_WORKER_AUTOSCALE=4,1

# Worker resource limits (prevents crashes and memory leaks)
# Max memory per worker before restart (in KB, 8000000 = 8GB)
CELERY_WORKER_MAX_MEMORY_PER_CHILD=8000000

# Task time limits (prevents hung tasks)
CELERY_TASK_TIME_LIMIT=3600          # Hard limit: 1 hour (task killed)
CELERY_TASK_SOFT_TIME_LIMIT=3000     # Soft limit: 50 minutes (warning)
