---
title: Installation
description: Launch LegalEase locally with Docker Compose.
navigation:
  icon: i-lucide-download
---

This guide walks through spinning up the full LegalEase stack using the provided Docker Compose configuration. The process normally takes less than 15 minutes, depending on how long model downloads take.

## Prerequisites

- Docker Engine 24+ and Docker Compose v2
- `make` utility (optional but recommended)
- 16 GB RAM minimum (32 GB recommended if you plan to transcribe long recordings)
- GPU with CUDA or ROCm if you want WhisperX acceleration (optional)
- Internet access for the initial container and model downloads

## 1. Clone the repository

```bash
git clone https://github.com/AlliecatOwO/legalease-ai.git
cd legalease-ai
```

## 2. Copy environment files

```bash
cp .env.example .env
cp backend/.env.example backend/.env
cp frontend/.env.example frontend/.env
```

Update the placeholders:

- `HF_TOKEN` (root `.env`) – optional; required only if you want Pyannote-based diarisation inside the transcription pipeline.
- `FORENSIC_EXPORTS_PATH` (root `.env`) – set to a host directory containing Cellebrite/AXIOM exports you want to mount read-only into the worker.
- `backend/.env` – adjust credentials or connection strings if your local ports clash with other services.
- `frontend/.env` – point `NUXT_PUBLIC_API_BASE` at your FastAPI hostname/port when running outside Docker.

## 3. Start infrastructure, run migrations, and pull models

```bash
make setup   # Starts infra containers, runs Alembic migrations, pulls default Ollama models
```

If you do not have `make`, run the equivalent:

```bash
docker compose up -d postgres redis qdrant minio neo4j ollama
docker compose exec backend alembic upgrade head
docker compose exec ollama ollama pull llama3.1
docker compose exec ollama ollama pull nomic-embed-text
```

## 4. Launch the application services

```bash
make up      # Starts backend, worker, beat, and frontend containers
```

Again, without `make`:

```bash
docker compose up -d backend worker beat frontend
```

The full stack exposes:

- Frontend dashboard – <http://localhost:3000>
- FastAPI docs – <http://localhost:8000/api/docs>
- MinIO console – <http://localhost:9001> (user: `legalease`, password: `legalease_dev_secret`)
- Qdrant dashboard – <http://localhost:6333/dashboard> (optional)
- Neo4j Browser – <http://localhost:7474> (user: `neo4j`, password: `legalease_dev`) if you plan to experiment with the knowledge graph code

## 5. Verify the deployment

1. Visit the dashboard (http://localhost:3000) – you should see the landing workspace.
2. Create a case via the UI.
3. Upload a sample PDF; within a few seconds the document should appear with `PROCESSING` status, then flip to `COMPLETED` once the Celery worker finishes.
4. Search for a keyword contained in the document; you should receive hybrid search results pointing at the relevant pages.
5. Optionally upload a short audio file to confirm transcription jobs are queued.

Monitor logs with:

```bash
docker compose logs -f backend worker
```

## 6. Stopping and cleaning up

- `make down` stops containers without deleting data.
- `make down-v` stops everything and removes named volumes (destructive).
- `make clean` is a convenience alias for `docker compose down`.

When you are ready to perform a full reset with sample data, follow the steps in `RESET.md`.
