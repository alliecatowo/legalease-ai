---
title: Features
description: In-depth guide to LegalEase AI features and capabilities.
navigation:
  icon: i-lucide-sparkles
---

This guide provides detailed information about all features available in LegalEase AI, from hybrid search to AI-powered analysis tools.

![Search Interface](search_page_no_sidebar.png)

## Hybrid Search Engine

LegalEase AI's search engine combines two powerful approaches to deliver the best possible results.

### BM25 Keyword Search

Traditional keyword matching using the BM25 algorithm provides:
- Exact phrase matching
- Term frequency analysis
- Document length normalization
- Relevance scoring based on term rarity

Best for: Finding exact quotes, legal terms, case numbers, and specific phrases.

### Semantic Vector Search

AI-powered semantic search using Sentence Transformers provides:
- Contextual understanding of queries
- Synonym and paraphrase matching
- Conceptual similarity detection
- Multi-lingual capabilities (limited)

Best for: Finding similar concepts, related topics, and documents with similar meaning.

### Hybrid Fusion

The hybrid approach combines both methods:
1. Queries are processed by both engines simultaneously
2. Results are retrieved from BM25 and vector search
3. Scores are normalized and fused using reciprocal rank fusion
4. Final results merge the best of both approaches

This delivers results that match both exact terms and semantic meaning, providing comprehensive coverage for legal research.

### Search Features

- **Sub-100ms Latency**: Results appear instantly (p95 < 100ms)
- **Bounding Box Highlighting**: Click results to see exact location in PDFs
- **Context Windows**: See surrounding text for better understanding
- **Relevance Scores**: Transparent scoring helps evaluate result quality
- **Advanced Filters**: Narrow by case, document type, and chunk type

![Case Management](cases_list.png)

## Case Management

Organize your document library with flexible case management.

### Creating and Managing Cases

Cases provide logical grouping for related documents:
- Create unlimited cases with descriptive names
- Add optional descriptions and metadata
- Archive cases when complete
- Delete cases (with warnings for non-empty cases)

### Loading Cases

Load multiple cases simultaneously to control search scope:
- Toggle cases on/off instantly
- Loaded cases are immediately searchable
- Unloaded cases are excluded from search results
- Load states persist across sessions

### Document Organization

Documents can be organized flexibly:
- Assign documents to cases during upload
- Move documents between cases later
- Documents can exist without case assignment
- Bulk operations for efficient organization

![Transcription Interface](transcription_speaker_diarization.png)

## Audio Transcription

Transform audio files into searchable, analyzable text with industry-leading speed and accuracy.

### Transcription Engine

Powered by WhisperX, an optimized version of OpenAI's Whisper model:
- **70x real-time speed**: Process 1 hour of audio in ~50 seconds
- **Word-level timestamps**: Precise timing for every word
- **High accuracy**: Optimized for legal terminology
- **Multiple formats**: WAV, MP3, M4A, FLAC, OGG support
- **GPU acceleration**: CUDA and ROCm support for maximum speed

### Speaker Diarization

Automatic speaker identification and separation:
- **Pyannote-based diarization**: State-of-the-art speaker segmentation
- **Configurable speakers**: Specify expected number for better accuracy
- **Temporal smoothing**: Reduces speaker switching noise
- **Color-coded output**: Visual distinction between speakers
- **AI name inference**: Attempts to identify speakers from context
- **Editable labels**: Manually correct or update speaker names

### Transcript Features

![Key Moments](transcription_key_moments.png)

- **Full-text search**: Find specific quotes instantly
- **Speaker filtering**: View segments by speaker
- **Statistics dashboard**: Talk time and contribution metrics
- **Export options**: DOCX, SRT, VTT, JSON formats
- **Timestamp navigation**: Jump to specific moments
- **Document linking**: Associate transcripts with case documents

## AI-Powered Analysis

Leverage local AI models for document understanding and analysis.

### Document Summarization

Generate concise summaries of lengthy documents:
- **LLM-based**: Uses Llama 3.1 via Ollama
- **Configurable length**: Control summary verbosity
- **Key points extraction**: Highlights important information
- **Context preservation**: Maintains legal context and terminology
- **100% local**: No external API calls or data sharing

### Entity Extraction

Automatically identify and extract legal entities:

**Person Names**: Parties, witnesses, attorneys, judges
**Organizations**: Law firms, companies, government agencies
**Dates**: Filing dates, deadlines, event dates
**Amounts**: Damages, fees, settlements, values
**Citations**: Case law, statutes, regulations, codes

Technologies used:
- **GLiNER**: General entity recognition with legal fine-tuning
- **LexNLP**: Specialized legal NLP for citations and amounts
- **Custom patterns**: Regular expressions for specific formats

### Smart Tagging

Automatic document categorization and metadata extraction:
- Document type classification (brief, contract, pleading, etc.)
- Topic identification
- Practice area detection
- Urgency/priority assessment
- Related document suggestions

### Knowledge Graphs

Visualize relationships between entities and documents:
- **Neo4j backend**: Graph database for relationship storage
- **Cytoscape.js frontend**: Interactive visualization
- **Multiple edge types**: Citations, mentions, co-occurrences, relationships
- **Graph algorithms**: Centrality, community detection, path finding
- **Export capabilities**: Export graphs as images or data files

Features:
- Click nodes to explore entity details
- Follow edges to understand relationships
- Filter by entity type or relationship type
- Zoom, pan, and rearrange layout
- Save graph layouts for future reference

![Document Viewer](document_with_overlay.png)

## PDF Viewer

Native PDF viewing with advanced features for legal document review.

### Viewing Features

- **High-fidelity rendering**: Precise reproduction of original documents
- **Zoom and pan**: Mouse wheel zoom, click-and-drag panning
- **Page navigation**: Thumbnails, page numbers, next/previous controls
- **Search highlighting**: Bounding boxes for search results
- **Print support**: Direct printing from viewer
- **Keyboard shortcuts**: Efficient navigation and control

### Search Integration

![Discovery Items](discovery_items.png)

Seamless integration with LegalEase AI search:
1. Click any search result
2. PDF opens to exact page
3. Matching text highlighted with bounding box
4. Context visible in surrounding text
5. Multiple highlights per page supported

### Bounding Box Precision

![Document Metadata](document_metadata.png)

Thanks to Docling's advanced parsing:
- Exact pixel coordinates for every text chunk
- Accurate highlighting even in complex layouts
- Support for tables, columns, and text boxes
- Visual feedback for search relevance

## Document Processing Pipeline

Automated pipeline for document ingestion and analysis.

### Upload Process

1. **File Upload**: Documents uploaded to MinIO object storage
2. **Metadata Extraction**: Basic file properties recorded
3. **Queue Dispatch**: Processing job sent to Celery worker
4. **Status Tracking**: Real-time progress updates

### Parsing with Docling

Docling extracts document structure and content:
- Text extraction with layout preservation
- Table recognition and extraction
- Section and heading detection
- Bounding box coordinates for all elements
- Metadata extraction (title, author, dates)

### Chunking Strategy

Documents are split into semantic chunks:
- **Titles**: Document and section titles
- **Sections**: Complete sections with context
- **Paragraphs**: Individual paragraphs
- **Tables**: Table content with headers
- **Lists**: List items with structure

Chunking strategy balances:
- Chunk size (for embedding model limits)
- Semantic coherence (maintaining meaning)
- Search granularity (precision vs. recall)
- Context preservation (surrounding information)

### Embedding Generation

Text chunks are embedded for semantic search:
- **Model**: all-MiniLM-L6-v2 Sentence Transformer
- **Dimension**: 384 dimensions per vector
- **Speed**: ~1000 chunks per second on CPU
- **Quality**: Balanced performance and accuracy

### Indexing

Processed content is indexed across multiple systems:
- **PostgreSQL**: Metadata and relational data
- **Qdrant**: Vector embeddings for semantic search
- **BM25 Index**: Keyword search index
- **Neo4j**: Entity relationships (after extraction)

## Privacy and Security

LegalEase AI is designed with privacy as a core principle.

### Local Processing

Everything happens on your infrastructure:
- No external API calls for AI processing
- No data sent to third-party services
- Complete control over data storage
- Air-gap deployment possible

### Data Storage

You control all data stores:
- **PostgreSQL**: Relational data (documents, cases, metadata)
- **Qdrant**: Vector embeddings (local deployment)
- **MinIO**: Object storage (S3-compatible, self-hosted)
- **Neo4j**: Knowledge graphs (local deployment)
- **Redis**: Cache and message broker (local)

### AI Models

All AI models run locally:
- **Ollama**: LLM inference (Llama 3.1)
- **Sentence Transformers**: Embeddings (local)
- **WhisperX**: Transcription (local)
- **GLiNER**: Entity extraction (local)

### Access Control

Current implementation:
- Single-tenant architecture
- Network-level access control via Docker
- File system permissions for data directories

Future roadmap:
- Multi-tenant support
- User authentication and authorization
- Role-based access control (RBAC)
- Audit logging

## Performance

LegalEase AI is optimized for speed and efficiency.

### Benchmarks

| Metric | Target | Typical |
|--------|--------|---------|
| Search Latency (p95) | <100ms | 50-80ms |
| Document Processing | <1 min per 100-page PDF | 30-45 seconds |
| Transcription Speed | ~70x real-time | 60-75x |
| UI Frame Rate | 60fps (16ms) | 60fps |
| Memory Usage | <8GB RAM | 4-6GB |
| Storage Overhead | ~2x original file size | 1.8-2.2x |

### Optimization Techniques

**Search:**
- Index optimization and caching
- Query planning and result caching
- Parallel processing for hybrid search
- Connection pooling for databases

**Document Processing:**
- Async task processing with Celery
- Batch embedding generation
- Incremental indexing
- Background job prioritization

**Transcription:**
- GPU acceleration (CUDA/ROCm)
- Batched inference
- Chunked processing for large files
- Parallel diarization pipeline

**UI:**
- Server-side rendering with Nuxt
- Code splitting and lazy loading
- Virtual scrolling for large lists
- PDF.js worker threads

## Integration

LegalEase AI is designed to integrate with your existing tools.

### API

Full RESTful API for programmatic access:
- **FastAPI backend**: Automatic OpenAPI documentation
- **Swagger UI**: Interactive API explorer at `/docs`
- **Authentication**: Token-based (planned)
- **Rate limiting**: Configurable (planned)

Key endpoints:
- `/api/documents` - Document management
- `/api/cases` - Case operations
- `/api/search` - Search queries
- `/api/transcriptions` - Audio transcription
- `/api/entities` - Entity extraction

### Export

Multiple export formats supported:
- **Documents**: PDF (original), text, JSON (metadata)
- **Search results**: JSON, CSV
- **Transcripts**: DOCX, SRT, VTT, JSON, plain text
- **Knowledge graphs**: GraphML, JSON, PNG/SVG
- **Entities**: JSON, CSV

### Import

Flexible import options:
- **Drag-and-drop**: Bulk upload via web interface
- **API upload**: Programmatic document ingestion
- **Bulk processing**: Directory watching (planned)
- **Integrations**: Email, cloud storage (planned)

### Webhooks

Event notifications for automation (planned):
- Document processing completion
- Search query execution
- Transcription completion
- Entity extraction completion
- Error notifications

## Configuration

LegalEase AI is configurable via environment variables and configuration files.

### Key Settings

**AI Models:**
- Ollama model selection
- Embedding model choice
- Whisper model size
- GLiNER entity types

**Processing:**
- Chunk size and overlap
- Concurrent workers
- Processing priorities
- Retry policies

**Search:**
- Hybrid fusion weights
- Result limits
- Context window size
- Filter defaults

**Storage:**
- Database connection strings
- MinIO bucket names
- Redis configuration
- Retention policies

For detailed configuration options, see the [Configuration](/docs/essentials/configuration) guide.
