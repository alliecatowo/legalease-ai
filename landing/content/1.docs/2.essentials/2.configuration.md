---
title: Configuration
description: Environment variables and tuning options for LegalEase.
navigation:
  icon: i-lucide-settings
---

LegalEase reads configuration from environment variables. This page highlights the most important settings and where they live.

## Environment files

| File | Purpose |
|------|---------|
| `.env` | Root-level settings used by Docker Compose (HF token, host volume mounts) |
| `backend/.env` | FastAPI + Celery configuration when running the backend outside Docker |
| `frontend/.env` | Nuxt runtime configuration |

### Root `.env`

```bash
# Optional: Hugging Face token for Pyannote diarisation
HF_TOKEN=hf_xxxxxxxx

# Path on the host that contains Cellebrite/AXIOM exports
FORENSIC_EXPORTS_PATH=/path/to/exports
```

The `FORENSIC_EXPORTS_PATH` directory is mounted read-only into the worker container at `/data/forensic-exports`.

### Backend `.env`

Used when you run FastAPI/Celery on the host instead of through Docker.

```bash
# Application metadata
APP_NAME=LegalEase
APP_VERSION=0.1.0
DEBUG=True

# Database connectivity
DATABASE_URL=postgresql+asyncpg://legalease:legalease@localhost:5432/legalease

# Redis & Celery
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# Qdrant
QDRANT_URL=http://localhost:6333
QDRANT_COLLECTION=legalease_documents

# MinIO
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=legalease
MINIO_SECRET_KEY=legalease_dev_secret
MINIO_BUCKET=legalease
MINIO_SECURE=False

# Ollama + transcription fallbacks
OLLAMA_BASE_URL=http://localhost:11434
OPENAI_API_KEY=sk-...   # optional; used when WhisperX is unavailable
```

When running inside Docker Compose, these values are injected through `docker-compose.yml` instead.

### Frontend `.env`

```bash
NUXT_PUBLIC_API_BASE=http://localhost:8000
```

Point this at your FastAPI instance. During local development you can export it inline (`NUXT_PUBLIC_API_BASE=http://localhost:8000 pnpm dev`).

## Docker-specific configuration

- All services are exposed on localhost ports. Adjust mappings in `docker-compose.yml` if they clash with existing infrastructure.
- Named volumes preserve data (`postgres_data`, `minio_data`, `qdrant_data`, etc.). Remove them with `make down-v` when you need a clean slate.
- GPU passthrough is enabled for backend, worker, and Ollama containers via the Docker Compose `deploy.resources` stanza. Remove it if you do not have CUDA/ROCm.

## Ollama models

Default models pulled by `make setup`:

- `llama3.1` – used for transcript summarisation
- `nomic-embed-text` – used for embedding fallbacks

Download additional models with:

```bash
make ollama-pull-mistral
make ollama-pull-llava
```

Update the backend settings via environment variables:

```bash
export OLLAMA_MODEL_SUMMARIZATION=mistral:7b
export OLLAMA_MODEL_TAGGING=llama3.1:8b
```

## Transcription tuning

The transcription API accepts optional parameters (language, diarisation toggle, min/max speakers, temperature, prompt). See `backend/app/api/v1/transcriptions.py` for full schema.

Environment variables that influence behaviour:

| Variable | Description |
|----------|-------------|
| `OPENAI_API_KEY` | Enables the Whisper API fallback when WhisperX is not available |
| `HF_TOKEN` | Enables Pyannote diarisation. Without it, a heuristic diariser is used. |
| `WHISPER_MODEL` (in code) | Default WhisperX model size (`medium` by default in the pipeline) |

## Logging and debugging

- Set `LOG_LEVEL=DEBUG` in `backend/.env` when troubleshooting.
- Celery emits structured logs; follow them with `docker compose logs -f worker`.
- Hybrid search results include `_score_debug` metadata describing BM25 and dense contributions. Use this to tune thresholds.

## Security considerations

- Replace default credentials (`legalease_dev_secret`, etc.) before running in shared environments.
- Configure HTTPS termination (e.g., via a reverse proxy) for production deployments.
- Authentication/authorisation is currently stubbed—do not expose the dashboard on the public internet without wrapping it behind your own auth gateway.
